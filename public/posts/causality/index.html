<!DOCTYPE html>
<html lang="en-us">
<head>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
  <link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Quasi-Experiments for Causal Inference | Yuan Meng</title>
  <link rel = 'canonical' href = 'https://www.yuan-meng.com/posts/causality/'>
  <meta name="description" content="Hi, this is Yuan. I&#39;m a computational cognitive science PhD candidate at UC Berkeley studying how kids and adults figure out causality and reinforce stereotypes through exploration and observations. Things I particularly like: Machine learning (predictive modeling, generative models, fairness), product analytics, cognitively inspired AI, guitar, symphonic metal, and Oxford commas.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Quasi-Experiments for Causal Inference" />
<meta property="og:description" content="&ldquo;Causation [&hellip;] is the cement of the universe.&rdquo; ‚Äî David Hume, Abstract
 Data scientists help the team make good decisions and good decisions rely on causation. Prof. Alison Gopnik always has the nicest example: While yellow fingers and smoking are both correlated with lung cancer, washing hands doesn&rsquo;t prevent cancer.
Randomized controlled experiments, or A/B tests, are the gold standard for establishing causality. Unfortunately, it&rsquo;s not always possible, feasible, or ethical to randomly assign people into different variants: In the example above, you can&rsquo;t in good conscience force someone to smoke, nor can you easily have them quit smoking." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.yuan-meng.com/posts/causality/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-11-11T00:00:00+00:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Quasi-Experiments for Causal Inference"/>
<meta name="twitter:description" content="&ldquo;Causation [&hellip;] is the cement of the universe.&rdquo; ‚Äî David Hume, Abstract
 Data scientists help the team make good decisions and good decisions rely on causation. Prof. Alison Gopnik always has the nicest example: While yellow fingers and smoking are both correlated with lung cancer, washing hands doesn&rsquo;t prevent cancer.
Randomized controlled experiments, or A/B tests, are the gold standard for establishing causality. Unfortunately, it&rsquo;s not always possible, feasible, or ethical to randomly assign people into different variants: In the example above, you can&rsquo;t in good conscience force someone to smoke, nor can you easily have them quit smoking."/>

  
  
    
  
  
  <link rel="stylesheet" href="https://www.yuan-meng.com/css/styles.94f653e9e151e28067a7c5dbbc4600cbd5a3c721e79faaf971e523c40f3b249b8e4f20bb57810dfffa8d559ca5c140fd56eb4cd9c0853113ad08e66afdb08bdd.css" integrity="sha512-lPZT6eFR4oBnp8XbvEYAy9WjxyHnn6r5ceUjxA87JJuOTyC7V4EN//qNVZylwUD9VutM2cCFMROtCOZq/bCL3Q=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://www.yuan-meng.com/images/favicon.ico" />

  
  
  
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">About</a></li>
         
        <li><a href="/posts">Writings</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://www.yuan-meng.com/posts/cocosci/" aria-label="Previous">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#" aria-label="Share">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f" aria-label="Facebook">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&text=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Twitter">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&title=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Linkedin">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&is_video=false&description=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Pinterest">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Quasi-Experiments%20for%20Causal%20Inference&body=Check out this article: https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f" aria-label="Email">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&title=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Pocket">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&title=Quasi-Experiments%20for%20Causal%20Inference" aria-label="reddit">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&name=Quasi-Experiments%20for%20Causal%20Inference&description=%26ldquo%3bCausation%20%5b%26hellip%3b%5d%20is%20the%20cement%20of%20the%20universe.%26rdquo%3b%20%e2%80%94%20David%20Hume%2c%20Abstract%0a%20Data%20scientists%20help%20the%20team%20make%20good%20decisions%20and%20good%20decisions%20rely%20on%20causation.%20Prof.%20Alison%20Gopnik%20always%20has%20the%20nicest%20example%3a%20While%20yellow%20fingers%20and%20smoking%20are%20both%20correlated%20with%20lung%20cancer%2c%20washing%20hands%20doesn%26rsquo%3bt%20prevent%20cancer.%0aRandomized%20controlled%20experiments%2c%20or%20A%2fB%20tests%2c%20are%20the%20gold%20standard%20for%20establishing%20causality.%20Unfortunately%2c%20it%26rsquo%3bs%20not%20always%20possible%2c%20feasible%2c%20or%20ethical%20to%20randomly%20assign%20people%20into%20different%20variants%3a%20In%20the%20example%20above%2c%20you%20can%26rsquo%3bt%20in%20good%20conscience%20force%20someone%20to%20smoke%2c%20nor%20can%20you%20easily%20have%20them%20quit%20smoking." aria-label="Tumblr">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&t=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Hacker News">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    
    <div id="toc">
      <nav id="TableOfContents"></nav>
    </div>
    
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        Quasi-Experiments for Causal Inference
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          <time datetime="2021-11-11 00:00:00 &#43;0000 UTC" itemprop="datePublished">2021-11-11</time>
          
        </div>
        
        
        <div class="article-read-time">
          <i class="far fa-clock"></i>
          
          14 minute read
        </div>
        
        
        <div class="article-category">
            <i class="fas fa-archive"></i>
            
            
            <a class="category-link" href="/categories/notes">notes</a>
            
        </div>
        
        
        <div class="article-tag">
            <i class="fas fa-tag"></i>
            
            
            <a class="tag-link" href="/tags/causal-inference" rel="tag">causal inference</a>
            
             ,  
            <a class="tag-link" href="/tags/quasi-experiment" rel="tag">quasi-experiment</a>
            
        </div>
        
      </div>
    </header>

  
    
    <div class="content" itemprop="articleBody">
      <blockquote>
<p>&ldquo;Causation [&hellip;] is the cement of the universe.&rdquo; ‚Äî David Hume, <em>Abstract</em></p>
</blockquote>
<p>Data scientists help the team make good decisions and good decisions rely on causation. <a href="http://alisongopnik.com/">Prof. Alison Gopnik</a> always has the nicest example: While yellow fingers and smoking are both correlated with lung cancer, washing hands doesn&rsquo;t prevent cancer.</p>
<p>Randomized controlled experiments, or A/B tests, are the gold standard for establishing causality. Unfortunately, it&rsquo;s not always possible, feasible, or ethical to randomly assign people into different variants: In the example above, you can&rsquo;t in good conscience force someone to smoke, nor can you easily have them quit smoking. Worse still, even if you&rsquo;ve run what seems like a well-controlled experiment, differences may arise from factors other than your treatment. For instance, say DoorDash A/B tested &ldquo;SOS pricing&rdquo; (treatment customers paid more for each order during peak hours) but <em>didn&rsquo;t</em> observe significant drops in delivery times in treatment vs. control. Is SOS pricing useless? Not necessarily ‚Äî A given market shares the same pool of dashers and customer; only the treatment &ldquo;paid the price&rdquo; but the control reaped the benefits for free (SOS pricing üëâ increased dasher supplies + decreased order demands üëâ shorter delivery times + fewer late orders), making the observed difference quite likely smaller than the true difference.</p>
<p>Where randomized controlled experiments are tricky, quasi-experiments (&ldquo;quasi&rdquo; means &ldquo;as if&rdquo; or &ldquo;almost&rdquo; in Latin) may help data scientists answer questions about causality. If you&rsquo;re interviewing with a marketplace company such as DoorDash, Uber, Lyft, Airbnb, etc. for which regular A/B testing can be problematic, chances are you&rsquo;re expected to have some knowledge of those &ldquo;non-traditional&rdquo; methods.</p>
<h1 id="switchbacks">Switchbacks</h1>
<p>For DoorDash to test SOS pricing properly, it&rsquo;s necessary to split the dasher and the customer pools either across space (different markets) or across time (different time of the day). In fact, they do both (DoorDash wrote a wonderful <a href="https://doordash.news/2018/02/14/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash/">blog post</a>).</p>
<figure><img src="https://miro.medium.com/max/1400/1*wTkgNdjmhOeMUjfGbpqzJQ.png"
         alt="DoorDash tests SOS pricing using switchbacks across time-market units" width="600"/><figcaption>
            <p>DoorDash tests SOS pricing using switchbacks across time-market units</p>
        </figcaption>
</figure>

<p>We can select multiple markets for experimentation and evenly divide each day in each market into small chunks, say, half an hour. Each time-market unit is randomly assigned to having or not having SOS pricing ‚Äî by contrast, randomization units in regular A/B testing would probably be deliveries. To examine whether SOS pricing is helpful, we can compare key metrics such as delivery times and order lateness between the treatment units and the control units after the switchback experiment.</p>
<p>To design effective switchback experiments, below are a few things to think over:</p>
<ol>
<li>
<p><strong>How fine should the time units be?</strong> Two hours, half an hour, or 10 minutes? Too coarse, there won&rsquo;t be enough randomization units; too granular, the market won&rsquo;t have time to respond to the change and the variance would probably be high (market trends are smoother over a longer period of time and more volatile in a shorter period). We can try a bunch of window sizes to see when we achieve a reasonably low standard error $\frac{\sigma}{\sqrt{n}}$ ($n$ is the number of time-market units).</p>
</li>
<li>
<p><strong>Time units in the same market are dependent</strong>. If we know how deliveries in LA are like at 11:30 AM, we can probably take a good guess about deliveries at 12:00 PM, even though pricing strategies may differ between these two units. To address the dependence issue, we can use <a href="https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-model"><strong>multilevel models</strong></a> where the <strong>pricing strategy is the &ldquo;fixed effect&rdquo;</strong> (captures the effect of the variable we&rsquo;re interested in) and <strong>time and markets are the &ldquo;random effects&rdquo;</strong> (capture group-level variation). Below is a toy implementation using the <code>lme4</code> package in R:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span style="color:#50fa7b">library</span>(lme4)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>sos <span style="color:#ff79c6">&lt;-</span> <span style="color:#50fa7b">lmer</span>(delivery_time <span style="color:#ff79c6">~</span> has_sos <span style="color:#ff79c6">+</span> (<span style="color:#bd93f9">1</span><span style="color:#ff79c6">|</span>market) <span style="color:#ff79c6">+</span> (<span style="color:#bd93f9">1</span><span style="color:#ff79c6">|</span>time), data<span style="color:#ff79c6">=</span>sb_data)
</code></pre></div><p>Moreover, we can use the &ldquo;<a href="https://stats.stackexchange.com/questions/50778/sandwich-estimator-intuition">Huber Sandwich Estimator</a>&rdquo; to compute variance, which doesn&rsquo;t make the independence assumption like ordinary least squares (OLS) do.</p>
</li>
<li>
<p><strong>Weight each time-market unit by the number of deliveries or not?</strong> The number of deliveries may well differ by time-market unit; it&rsquo;s natural to think units with more deliveries should count more towards the average metric value in a given variant ($\frac{\sum_{i}^{n}y_i w_i}{n}$; $y_i$: metric value in unit $i$; $w_i$: delivery volume in unit $i$). In practice, DoorDash data scientists use the simple, rather than weighted, average in each variant ($\frac{\sum_{i}^{n}y_i}{n}$). One justification <a href="https://doordash.news/2018/02/14/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash/">they gave</a> is that randomization units are time-market units, so delivery-level information can be ignored.</p>
</li>
<li>
<p><strong>Is the feature change visible?</strong> Switchbacks are great for testing invisible algorithmic changes (e.g., ranking, pricing) but terrible for visible UI changes; in the latter case, users are bound to be confused if they are switched back and forth between the old and the new designs.üòµ‚Äçüí´</p>
</li>
</ol>
<h1 id="difference-in-differences-did">Difference in Differences (DiD)</h1>
<p><del>Facebook</del> Meta famously did a country test before <a href="https://developers.facebook.com/videos/f8-2017/how-we-shipped-reactions/">shipping &ldquo;Reactions&rdquo;</a>. It used to be the case that users could only like a post but not express other emotions such as anger or sadness. If someone posted about a loved one passing away, it seemed inappropriate to like it, yet many might not want to leave a comment (e.g., too effortful, not close enough). Meta data scientists hypothesized that, if a wider range of reactions were allowed, people would be more willing to engage with posts. They could run a regular A/B test, randomly assigning users to having or not having reactions. However, if users in different variants are in the same friend circle, you risk creating bad user experiences: Say a treatment user reacted to a post by a control user, the latter would not be able to see it and engage back.</p>
<p>To alleviate this worry, Meta tested Reactions in different countries, assuming users didn&rsquo;t interact folks from other countries. In this example, country A (green) had reactions while country B (red) didn&rsquo;t. The $y-$axis tracks the number of posts reacted (including likes) to per user, which Meta aimed to drive up.</p>
<figure><img src="https://www.dropbox.com/s/s9x78epex3zw1lk/reactions.png?raw=1"
         alt="The # of posts reacted to per user before and after launching Reactions" width="500"/><figcaption>
            <p>The # of posts reacted to per user before and after launching Reactions</p>
        </figcaption>
</figure>

<ul>
<li>
<p><strong>Assumptions</strong>: 1) Differences between countries are the same at different points in time and 2) the time effect is the same across different countries.</p>
</li>
<li>
<p><strong>Analysis</strong>: Under those assumptions, if Reactions had no effect at all, the green line would be parallel to the red line after feature launching. In my badly drawn illustration, <strong>the difference between the actual green line and the dotted green line</strong> (the counterfactual under the null hypothesis) <strong>is the treatment effect</strong>. This method is called <strong>&ldquo;difference in differences (DiD)&quot;</strong>.</p>
</li>
<li>
<p><strong>Formalism</strong>: $y = \beta_0 + \beta_1 D_{post} + \beta_2 D_{treatment} + \beta_3 D_{post} D_{treatment} + \beta_4 X + \epsilon$</p>
<ul>
<li><strong>Variables</strong>: $y$: the value of the success metric (e.g., # of posts reacted to per user); $D_{post}$: whether an observation came from the pre-launching or the post-launching period (0: pre, 1: post); $D_{treatment}$: whether an observation was in treatment or control (1: treatment, 0: control); $X$: covariates (e.g., country/user demographics)</li>
<li><strong>Interpretation</strong>: The interaction $\beta_3$ is the difference in differences</li>
</ul>
</li>
</ul>
<p>DiD is an old method that&rsquo;s fast but crude: Both of the assumptions above can be easily violated (e.g., between-country differences may change over time and time effects may differ by country), resulting in invalid conclusions. As we&rsquo;ll see in a minute, more sophisticated methods such as synthetic control and CausalImpact are developed to make causal inference without these rigid assumptions.</p>
<h1 id="synthetic-control-synth">Synthetic Control (Synth)</h1>
<p>Sometimes we can&rsquo;t but roll out a feature to all users at once (e.g., due to urgency or the worry that treatment users might leak confidential information to the Internet) but still wish to know what would be like without this new feature.</p>
<p>A simple thing to do is compare metrics before and after the launch. However, changes may result from what&rsquo;s happening in the world besides the feature launch.</p>
<blockquote>
<p>&ldquo;The outside world often has a much larger effect on metrics than product changes do.&rdquo; Jan Overgoor, <a href="https://medium.com/airbnb-engineering/experiments-at-airbnb-e2db3abf39e7"><em>Experiments at Airbnb</em></a></p>
</blockquote>
<p>Synthetic control comes to the rescue: We can build a model that learns the relationship between certain predictors and the target metric in the pre-launching period and then use the learned relationship to forecast how the metric would look later if the feature wasn&rsquo;t launched. This method is called &ldquo;<em>synthetic</em> control&rdquo; in that there never was an actual control: The model&rsquo;s prediction simulates a &ldquo;parallel universe&rdquo; without the feature launch and <strong>the difference between the synthetic control and what actually happened after launching is the treatment effect</strong>.</p>
<p>Uber data scientists used synthetic control to examine the effect of giving drivers heads up about cash trips. In markets like India where not a lot of people carry credit cards, riders often pay drivers in cash. Cash trips may be inconvenient to the drivers as they need to wire commission fees to Uber later; however, some drivers may prefer to receive cash. Uber wanted to test whether showing drivers whether a trip was a cash trip in advance might affect how many cash trips they took.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/j5DoJV5S2Ao" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>Uber faced the same problem as DoorDash did: A market shares the same pool of drivers and riders; if the treatment takes more or fewer cash trips, the control will have fewer or more cash trips to take. Can Uber use switchbacks like DoorDash? Nice guess, but that would be inappropriate: Imagine, a driver was in treatment and received heads up about cash trips; when they are switched to control, they&rsquo;ll naturally think a trip without a heads up is non-cash rather than type unknown.</p>
<figure><img src="https://www.dropbox.com/s/tebslmo8g1agtlm/synthetic_controk.png?raw=1"
         alt="Uber used synthetic control to test heads up to drivers about cash trips (to report to stakeholders, you can average the differences over time)" width="600"/><figcaption>
            <p>Uber used synthetic control to test heads up to drivers about cash trips (to report to stakeholders, you can average the differences over time)</p>
        </figcaption>
</figure>

<p>Instead, Uber data scientists trained a time-series model to predict the number of cash trips had the feature not been rolled out in a city (&ldquo;synthetic city&rdquo;) and compared the prediction with the actual number of cash trips after the rollout (&ldquo;treatment city&rdquo;). The difference between the two shows that telling drivers about the trip type encouraged them to take more cash trips.</p>
<p>To successfully implement synthetic control, you gotta be a good time-series modeler and are <em>not</em> tempted to tweak your model until you find treatment effects.</p>
<h1 id="did--synth--causalimpact">DiD + Synth üëâ CausalImpact</h1>
<p><a href="https://google.github.io/CausalImpact/CausalImpact.html">CausalImpact</a> combines ideas from DiD and synth and is the best of both worlds:</p>
<ul>
<li><strong>Unlike synth</strong>, there is an actual control group not exposed to the new feature üëâ this means CausalImpact can use control data from both pre- and post-launching periods whereas synth only makes use of the pre-launching data</li>
<li><strong>Unlike DiD</strong>, we don&rsquo;t need to assume the same regional differences across time or the same time effects across regions üëâ instead, we can build a Bayesian structural time-series model using the control data to predict a &ldquo;synthetic treatment&rdquo; trend and compare it with the actual treatment data</li>
</ul>
<p>Google open-sourced the <code>CausalImpact</code> R package. Below is a toy example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span style="color:#50fa7b">library</span>(CausalImpact)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>impact <span style="color:#ff79c6">&lt;-</span> <span style="color:#50fa7b">CausalImpact</span>(data, pre.period, post.period)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span><span style="color:#50fa7b">plot</span>(impact)
</code></pre></div><figure><img src="https://www.dropbox.com/s/cwtreolbp7h9477/causalimpact.png?raw=1"
         alt="Example results: The top panel shows the actual treatment (solid line) and the synthetic treatment predicted by the model (dashed line) and the middle panel shows the difference between the two before and after launching" width="550"/><figcaption>
            <p>Example results: The top panel shows the actual treatment (solid line) and the synthetic treatment predicted by the model (dashed line) and the middle panel shows the difference between the two before and after launching</p>
        </figcaption>
</figure>

<p>HelloFresh used CausalImpact to measure the impact of a YouTube ad campaign across geographic regions. The treatment saw the ads and the control didn&rsquo;t. HelloFresh data scientists used control data to predict what the treatment conversation rate would look like without the campaign and compared it with the actual observation ‚Äî as mentioned, the impact of this ad campaign lies in the difference.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/KEhJNM5K73A" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h1 id="propensity-score-matching-psm">Propensity Score Matching (PSM)</h1>
<p>Care for another HelloFresh example? Say their data scientists wanna know if users who click on Food Network ads are more likely to buy from HelloFresh.</p>
<p>Here&rsquo;s the problem if we directly compare clickers vs. non-clickers: Ads are usually personalized, so those who are shown Food Network ads likely differ from those who aren&rsquo;t; if we do observe a difference in HelloFresh purchases, should we attribute it to the ads or individual differences? Chances are, those interested in cooking are both inclined to click on Food Network ads and buy from HelloFresh.</p>
<figure><img src="https://www.dropbox.com/s/iexwhzrjzzxtokq/propensity.png?raw=1"
         alt="It&amp;rsquo;s hard to tell if ad clicking causes HelloFresh purchases or if clicks and purchases are both driven by a third variable: Interest in cooking" width="550"/><figcaption>
            <p>It&rsquo;s hard to tell if ad clicking causes HelloFresh purchases or if clicks and purchases are both driven by a third variable: Interest in cooking</p>
        </figcaption>
</figure>

<p>Propensity score matching (PSM) is a solution: We can build a model (using user demographics or past behaviors) to predict the probability that a given user is shown any Food Network ads and match users with high exposure probability but didn&rsquo;t click with those who had similar probability and clicked. Presumably, matched users have the same &ldquo;propensity&rdquo; to click on ads, so downstream differences in HelloFresh purchases can be attributed to the act of ad clicking.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/gaUgW7NWai8" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>The idea behind PSM sounds simple but it&rsquo;s tricky <a href="https://cran.r-project.org/web/packages/MatchIt/vignettes/matching-methods.html">how we can match users</a>:</p>
<ol>
<li><strong>Greedy vs. optimal</strong>: For each of the $N$ users in Group A, we can iterate through each of the $N$ users in Group B to find the best match üëâ time complexity: $O(N^2)$. However, this fast approach doesn&rsquo;t guarantee optimal results on the group level. Alternatively, we can exhaust all one-to-one match combinations to find the one that minimizes total within-pair differences üëâ this optimal approach is computationally expensive; time complexity: $O(N!)$</li>
<li><strong>Constraints</strong>: We can constrain what we consider as a match. For instance, we can set a threshold on the largest propensity score difference allowed for matched pairs (caliper matching). Another common constraint is whether we only consider one-to-one matching or if we allow one-to-many or even many-to-many matching.</li>
</ol>
<p>Matching algorithms are worth dedicating an entire book to; for data science interviews, it&rsquo;s enough to recognize when to use PSM and know what the &ldquo;propensity&rdquo; is.</p>
<h1 id="regression-discontinuity-design-rdd">Regression Discontinuity Design (RDD)</h1>
<p>Consider another DoorDash example. Late orders anger hungry customers; the later, the worse. Frustrated customers may order less in the future or even churn, resulting in lower lifetime values (LTVs). To make things slightly better, DoorDash automatically issues a refund to orders $\geq$ 30 minutes late. How does it impact LTV?</p>
<p>It&rsquo;s unfair to randomly assign customers into getting or not getting a refund, but it&rsquo;s also wrong to compare LTV between those who received or didn&rsquo;t receive refunds, since average lateness is likely higher in the former than in the latter.</p>
<p>To answer this question, we can use a regression discontinuity design (RDD), using order lateness (minutes late) and refund status (received or not) to predict LTV. As we can see in the figure below, the upward &ldquo;jump&rdquo; right after the 30-minute cutoff shows auto-refunding saved DoorDash&rsquo;s customer LTV, albeit not a lot.</p>
<figure><img src="https://www.dropbox.com/s/vz60f040euu0465/rdd.png?raw=1"
         alt="DoorDash uses regression discontinuity design (RDD) to measure the impact of auto-refunding on customer LTVs when orders arrive late" width="550"/><figcaption>
            <p>DoorDash uses regression discontinuity design (RDD) to measure the impact of auto-refunding on customer LTVs when orders arrive late</p>
        </figcaption>
</figure>

<ul>
<li><strong>Assumptions</strong>: Trajectories of &ldquo;near-winners&rdquo; (orders 31 minutes late) and &ldquo;near-losers&rdquo; (orders 29 minutes late) would have been the same without the treatment (refunding), so discontinuity can be attributed to treatment effects.</li>
<li><strong>Formalism</strong>: $y = f(X) + \beta D + \epsilon$ üëâ $y$: the outcome variable (e.g., LTV); $X$: the &ldquo;running variable&rdquo; that has continuous effects on the outcome (e.g., order lateness); $D$: whether treatment was assigned (0: not refunded, 1: refunded)</li>
<li><strong>Types</strong>: Depending on whether the cutoff is deterministic, RDD has <a href="https://scholar.princeton.edu/sites/default/files/jmummolo/files/rdd_jm.pdf">two types</a>
<ul>
<li><strong>Sharp (deterministic)</strong>: Orders $\geq$ 30 minutes late definitely receive a refund and those $&lt;$ 30 minutes late definitely don&rsquo;t</li>
<li><strong>Fuzzy (probabilistic)</strong>: The admission office has a suggested SAT cutoff, but students with lower scores might still get in through special programs</li>
</ul>
</li>
</ul>
<p>If the outcome is naturally &ldquo;jumpy&rdquo; around the cutoff (people suddenly get hungry 30 minutes after the ETA), you may wrongly attribute discontinuity to treatment.</p>
<h1 id="regress-it-out">&ldquo;Regress It Out&rdquo;</h1>
<p>Continuing with the regression idea, we can statistically control for covariates by &ldquo;regressing them out&rdquo;. Say we wanna know how much gender impacts income, we can put potential confounders like education and age in the same model and look at the slope of gender with all else being held the same. If this slope is much steeper than a horizontal line, then we can probably claim that gender affects income.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>bias <span style="color:#ff79c6">&lt;-</span> <span style="color:#50fa7b">lm</span>(income <span style="color:#ff79c6">~</span> gender <span style="color:#ff79c6">+</span> education <span style="color:#ff79c6">+</span> age, data<span style="color:#ff79c6">=</span>data)
</code></pre></div><p>While simple and useful, this method is not always appropriate (<a href="https://journals.sagepub.com/doi/pdf/10.1177/2515245917745629">Rohrer, 2018</a>):</p>
<ul>
<li><strong>Colliders</strong>: If $X$ is the common effect of $Y$ and $Z$ ($Y \rightarrow X \leftarrow Z$), controlling for $X$ would result in spurious correlation between $Y$ and $Z$.
<ul>
<li><strong>Example</strong>: Warm and competent candidates tend to be successful. In other words, a job offer is the common effect of warmth and competence. Since all of our colleagues were once successful candidates (i.e., interview results are &ldquo;controlled for&rdquo;), when we look around in the office, almost everyone seems warm and competent. If not careful, we may jump to the conclusion that these two traits are intrinsically linked.</li>
</ul>
</li>
<li><strong>Mediators</strong>: If $X$ influences $Y$ through $Z$ ($X \rightarrow Y \rightarrow Z$), controlling for $Y$ leads to the false conclusion that $X$ and $Y$ have no relationship at all.
<ul>
<li><strong>Example</strong>: Family wealth impacts education and education impacts future income. However, when we see PhD students (i.e, the education level is controlled for) from different socioeconomic backgrounds making roughly the same amount of $$ after graduation, we may falsely conclude that there&rsquo;s no such thing as generational wealth, at least among PhD&rsquo;s.</li>
</ul>
</li>
</ul>
<p>Since we don&rsquo;t always know how variables are related to one another (which we can represent using Bayesian networks), statistical control may hurt unexpectedly.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<hr>
<h1 id="summary">Summary</h1>
<p>As a cognitive scientist, I&rsquo;m writing a dissertation on how people think about causality intuitively. As a data scientist interested in causal inference, it&rsquo;s cool to see how human intuitions and formal methods conversage: For both, the heart of causality is <strong>counterfactuals</strong> ‚Äî worlds that could have been but never came to be, as well as <strong>intervention</strong> ‚Äî what we can do to make a difference.</p>
<p>Not that long ago, causal inference was rather niche in data science; I&rsquo;m happy to see it quickly gaining popularity in recently years. To summarize what I wrote:</p>
<ul>
<li>
<p><strong>Intervention and counterfactuals</strong>: The common philosophical assumption behind DiD, synth, CausalImpact, and RDD is that if we don&rsquo;t do anything (e.g., launching a new feature), nothing will happen; since something did happen, then what we did had an impact. This falls under the <a href="https://plato.stanford.edu/entries/causation-mani/#Inte">interventionist</a> view of causation: We know A causes B when <em>iif</em> doing A makes B happen. These methods differ in how they construct the counterfactual world without the treatment.</p>
</li>
<li>
<p><strong>Statistical control</strong>: Apart from what we do, lots of things in the world can make a difference to the outcome. Both PSM and regression hold potential confounders constant and examine whether the variable we&rsquo;re most interested in influences the outcome. We need to be careful that controlling for wrong variables (e.g., common effects and mediators) can lead to wrong conclusions.</p>
</li>
</ul>
<h1 id="resources">Resources</h1>
<ol>
<li><a href="https://www.ai-expo.net/northamerica/wp-content/uploads/2018/11/1500-Jessica-Lachs-DoorDash-DATA-STRAT-V1.pdf">Lessons Learned on Experimentation @DoorDash</a></li>
<li><a href="https://doordash.news/2018/02/14/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash/">Switchback Tests and Randomized Experimentation Under Network Effects at DoorDash</a></li>
<li><a href="https://eng.uber.com/xp/">Under the Hood of Uber&rsquo;s Experimentation Platform</a></li>
<li>Experimentation in a Ridesharing Marketplace by Lyft (<a href="https://eng.lyft.com/experimentation-in-a-ridesharing-marketplace-b39db027a66e#.djox1933t">Part 1</a>, <a href="https://eng.lyft.com/https-medium-com-adamgreenhall-simulating-a-ridesharing-marketplace-36007a8a31f2#.g9b34i3gm">Part 2</a>, <a href="https://eng.lyft.com/experimentation-in-a-ridesharing-marketplace-f75a9c4fcf01">Part 3</a>)</li>
<li><a href="https://towardsdatascience.com/causal-inference-using-synthetic-control-the-ultimate-guide-a622ad5cf827">Causal Inference Using Synthetic Control: The Ultimate Guide</a></li>
<li><a href="https://www.youtube.com/watch?v=GTgZfCltMm8">Inferring the Effect of an Event Using CausalImpact</a></li>
<li><a href="https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X">The Book of Why: The New Science of Cause and Effect </a></li>
<li><a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html">Causal Inference for The Brave and True</a></li>
<li><a href="https://youtu.be/HPC42U9xtQY">Python and the Holy Grail of Causal Inference</a></li>
<li>Liu, T., Ungar, L., &amp; Kording, K. (2021). Quantifying causality in data science with quasi-experiments. <em>Nature Computational Science</em>, 1(1), 24-32. (<a href="https://www.nature.com/articles/s43588-020-00005-8.pdf">PDF</a>)</li>
</ol>
<hr>
<blockquote>
<p><a href="https://www.causalscience.org/">Causal Data Science Meeting 2021</a> takes place between November 15 and 16!</p>
</blockquote>
<figure><img src="https://www.dropbox.com/s/1dlnw8sr12ifr0m/pearl.png?raw=1" width="500"/>
</figure>


    </div>
  </article>

  
  






  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">About</a></li>
         
          <li><a href="/posts">Writings</a></li>
        
      </ul>
    </div>

    
    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents"></nav>
    </div>
    

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f" aria-label="Facebook">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&text=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Twitter">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&title=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Linkedin">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&is_video=false&description=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Pinterest">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Quasi-Experiments%20for%20Causal%20Inference&body=Check out this article: https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f" aria-label="Email">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&title=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Pocket">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&title=Quasi-Experiments%20for%20Causal%20Inference" aria-label="reddit">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&name=Quasi-Experiments%20for%20Causal%20Inference&description=%26ldquo%3bCausation%20%5b%26hellip%3b%5d%20is%20the%20cement%20of%20the%20universe.%26rdquo%3b%20%e2%80%94%20David%20Hume%2c%20Abstract%0a%20Data%20scientists%20help%20the%20team%20make%20good%20decisions%20and%20good%20decisions%20rely%20on%20causation.%20Prof.%20Alison%20Gopnik%20always%20has%20the%20nicest%20example%3a%20While%20yellow%20fingers%20and%20smoking%20are%20both%20correlated%20with%20lung%20cancer%2c%20washing%20hands%20doesn%26rsquo%3bt%20prevent%20cancer.%0aRandomized%20controlled%20experiments%2c%20or%20A%2fB%20tests%2c%20are%20the%20gold%20standard%20for%20establishing%20causality.%20Unfortunately%2c%20it%26rsquo%3bs%20not%20always%20possible%2c%20feasible%2c%20or%20ethical%20to%20randomly%20assign%20people%20into%20different%20variants%3a%20In%20the%20example%20above%2c%20you%20can%26rsquo%3bt%20in%20good%20conscience%20force%20someone%20to%20smoke%2c%20nor%20can%20you%20easily%20have%20them%20quit%20smoking." aria-label="Tumblr">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fwww.yuan-meng.com%2fposts%2fcausality%2f&t=Quasi-Experiments%20for%20Causal%20Inference" aria-label="Hacker News">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu-toggle" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;" aria-label="Menu">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
        <a id="toc-toggle" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;" aria-label="TOC">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share-toggle" class="icon" href="#" onclick="$('#share-footer').toggle();return false;" aria-label="Share">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2021  Yuan Meng 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">About</a></li>
         
        <li><a href="/posts">Writings</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>

<script src=/js/code-copy.js></script>




</html>
